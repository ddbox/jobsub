#!/usr/bin/env python

import os
import sys
import stat
import commands
import re
import datetime
import time
from JobsubConfigParser import JobsubConfigParser
import xml.etree.ElementTree as ET

docString = """
 $Id$
"""
manual = """
INTRODUCTION
============
jobsub_submit_dag is an application which generates and submits a HTCondor 
DAG (directed acyclic graph) of jobs.  For purposes of illustration, consider
an example where you have 5 jobs A,B,C,D,E, that you want to run using condor. 
Job B requires A to run first, C and D require the output form B, 
and E requires the input from C and D.
A graphic representation would be:

                      A
                      |
                      B
                     / \\
                    C   D
                     \ /
                      E

Job A can be submitted submitted to condor 
using the command jobsub_submit (stuff) file//:jobA.sh, 
job B by jobsub_submit (stuff)  file://jobB.sh, etc.

These commands can be put in a jobsub_submit_dag input file which
will run them in the specified order.


INPUT FILE BASICS 
=================
The input file for the DAG generator in this example would look like this:

<serial>
jobsub_submit (stuff)  file://jobA.sh
jobsub_submit (stuff)  file://jobB.sh
</serial>
<parallel>
jobsub_submit (stuff)  file://jobC.sh
jobsub_submit (stuff)  file://jobD.sh
</parallel>
<serial>
jobsub_submit (stuff) file://jobE.sh
</serial>


RUNNING A DAG
==============
jobsub_submit_dag (options) file://input_file_1 will perform the following steps:
1) transport 'input_file_1' to the jobsub server
2) generate an HTCondor DAG based on the input_file
3) submit it to the batch server
4) optionally send an email report when all the  jobs in the DAG complete


SUB_DAGS, i.e. A DAG OF DAGS
===================================

jobsub_submit_dag commands will work in input files, and can be mixed in with
regular jobsub_submit commands.  Care must be taken not to create a circular 
chain of submissions.  If the command detects a circular submission it will
halt with an appropriate error message.


Many jobsub_submit commands generate a DAG internally, for example 
jobsub_submit -N (some integer) --maxConncurrent (some integer)
and jobsub_submit -N (some integer)--dataset_definition (SAM dataset definition)

The following input file fragment would run two dags sequentially:

<serial>
jobsub_submit --continue-on-failure -N 10 --maxConcurrent 5  file://jobA.sh
jobsub_submit_dag --continue-on-failure   file://input_dag_B.sh
</serial>






INPUT FILE MACROS
============
(Feature broked during transition to client/server architecture.  Documentation omitted until this feature fixed)

BEGINJOB AND FINISHJOB SCRIPTS
=============================
(Feature broked during transition to client/server architecture.  Documentation omitted until this feature fixed)



SERVER OPTIONS
==============

--maxConcurrent (integer)  Run only (integer) jobs from the DAG at any given time.
                           Useful for protecting shared resources.

--continue-on-failure      Override the default behavior of a DAG which is to not
                           run dependent or 'downstream' jobs if a job fails.

--generate-email-summary   Email a report when the last job in the DAG completes.
                           This option sets the  --continue-on-failure condition
                           


"""
usage = """
usage: %s -i input_file [-o output_dag] [-h(elp)] [-s(ubmit)] [--maxConcurrent  max_concurrent_jobs ] [--generate-email-summary]

for detailed instructions on how to use:
%s -manual | less
"""
cmd_file_dummy = """
universe      = vanilla
executable    = /opt/jobsub/server/tools/returnOK.sh
output     = returnOK_$(Cluster).$(Process).{0}.out
error      = returnOK_$(Cluster).$(Process).{0}.err
log        = returnOK_$(Cluster).$(Process).{0}.log
"""
wrap_file_dummy = """#!/bin/sh
#
exit 0
"""


class L(list):
    """
    A subclass of list that can accept additional attributes.
    Should be able to be used just like a regular list.

    The problem:
    a = [1, 2, 4, 8]
    a.x = "Hey!" # AttributeError: 'list' object has no attribute 'x'

    The solution:
    a = L(1, 2, 4, 8)
    a.x = "Hey!"
    print a       # [1, 2, 4, 8]
    print a.x     # "Hey!"
    print len(a)  # 4

    You can also do these:
    a = L( 1, 2, 4, 8 , x="Hey!" )                 # [1, 2, 4, 8]
    a = L( 1, 2, 4, 8 )( x="Hey!" )                # [1, 2, 4, 8]
    a = L( [1, 2, 4, 8] , x="Hey!" )               # [1, 2, 4, 8]
    a = L( {1, 2, 4, 8} , x="Hey!" )               # [1, 2, 4, 8]
    a = L( [2 ** b for b in range(4)] , x="Hey!" ) # [1, 2, 4, 8]
    a = L( (2 ** b for b in range(4)) , x="Hey!" ) # [1, 2, 4, 8]
    a = L( 2 ** b for b in range(4) )( x="Hey!" )  # [1, 2, 4, 8]
    a = L( 2 )                                     # [2]
    shamelessy lifted from:
    https://code.activestate.com/recipes/579103-python-addset-attributes-to-list/
    """

    def __new__(self, *args, **kwargs):
        return super(L, self).__new__(self, args, kwargs)

    def __init__(self, *args, **kwargs):
        if len(args) == 1 and hasattr(args[0], '__iter__'):
            list.__init__(self, args[0])
        else:
            list.__init__(self, args)
        self.__dict__.update(kwargs)

    def __call__(self, **kwargs):
        self.__dict__.update(kwargs)
        return self


class DagParser(object):

    def __init__(self):

        self.jobList = []
        self.jobNameList = []
        self.macroList = []
        self.beginJobList = []
        self.finishJobList = []

        self.jobDict = {}
        self.jobNameDict = {}
        self.macroDict = {}
        self.beginJobDict = {}
        self.finishJobDict = {}

        self.processingMacros = False
        self.processingSerial = False
        self.processingParallel = False
        self.processingBeginJob = False
        self.processingFinishJob = False
        self.redundancy = 0
        self.condor_tmp = os.environ.get("CONDOR_TMP")
        self.jnum = 1
        self.pnum = 1
        self.snum = 1
        self.nodeDict = {}
        self.dagDict = {}
        self.pcList = []
        self.condor_cmd_list = []

#######################################################################

    def startSerial(self, s):

        s = s.lower()
        if s.find("<serial>") >= 0:
            self.processingSerial = True
            return True
        return False

    def endSerial(self, s):

        s = s.lower()
        if s.find("</serial>") >= 0:
            self.processingSerial = False
            return True
        return False

#######################################################################

    def startParallel(self, s):

        s = s.lower()
        if s.find("<parallel>") >= 0:
            self.processingParallel = True
            return True
        return False

    def endParallel(self, s):

        s = s.lower()
        if s.find("</parallel>") >= 0:
            self.processingParallel = False
            return True
        return False

#######################################################################

    def startBeginJob(self, s):
        s = s.lower()
        if s.find("<beginjob>") >= 0:
            self.processingBeginJob = True
            return True
        return False

    def endBeginJob(self, s):
        s = s.lower()
        if s.find("</beginjob>") >= 0:
            self.processingBeginJob = False
            return True
        return False

    def isInBeginJob(self, s):
        if self.startBeginJob(s):
            self.processingBeginJob = True
        return self.processingBeginJob

    def processBeginJob(self, line):
        if self.endBeginJob(line):
            self.processingBeginJob = False
        else:
            line = line.strip()
            self.beginJobList.append(line)
            # print "self.beginJobList=",self.beginJobList

#######################################################################

    def startFinishJob(self, s):
        s = s.lower()
        if s.find("<finishjob>") >= 0:
            self.processingFinishJob = True
            return True
        return False

    def endFinishJob(self, s):
        s = s.lower()
        if s.find("</finishjob>") >= 0:
            self.processingFinishJob = False
            return True
        return False

    def isInFinishJob(self, s):
        if self.startFinishJob(s):
            self.processingFinishJob = True
        return self.processingFinishJob

    def processFinishJob(self, line):
        if self.endFinishJob(line):
            self.processingFinishJob = False
            self.finishJobList.append("mailer.py ")
        else:
            line = line.strip()
            self.finishJobList.append(line)
#######################################################################

    def startMacros(self, s):
        s = s.lower()
        if s.find("<macros>") >= 0:
            self.processingMacros = True
            return True
        return False

    def endMacros(self, s):
        s = s.lower()
        if s.find("</macros>") >= 0:
            self.processingMacros = False
            return True
        return False

    def isInMacros(self, s):
        if self.startMacros(s):
            self.processingMacros = True
        return self.processingMacros

    def processMacro(self, line):
        # print "processMacro input=",line
        if self.endMacros(line):
            self.processingMacros = False
        elif line.find("=") >= 0:
            [a, b] = line.split("=")
            a = a.strip()
            b = b.strip()
            self.macroList.append(a)
            self.macroDict[a] = b
            if (b.find("`") == 0):
                if (b.find("`", 1) == (len(b) - 1)):
                    cmd = b[1:len(b) - 1]
                    (retVal, val) = commands.getstatusoutput(cmd)
                    if retVal == 0:
                        self.macroDict[a] = val

#######################################################################

    def nameNode(self, elem):
        #global snum,pnum,jnum, nodeDict
        if elem.attrib.has_key('name'):
            self.nodeDict[elem.attrib['name']] = elem
            return
        if elem.tag == 'serial':
            elem.attrib['name'] = 'Serial_%s' % (self.snum)
            self.snum += 1
        if elem.tag == 'parallel':
            elem.attrib['name'] = 'Parallel_%s' % (self.pnum)
            self.pnum += 1
        if elem.tag == 'job':
            elem.attrib['name'] = 'Job_%s' % (self.jnum)
            self.jnum += 1
        if elem.tag == 'dag':
            elem.attrib['name'] = 'dag'
        self.nodeDict[elem.attrib['name']] = elem

    def labelTree(self, elem):
        self.nameNode(elem)
        l = list(elem)
        if len(l):
            for i2 in range(0, len(l)):
                x = l[i2]
                self.nameNode(x)
                l2 = list(x)
                if len(l2):
                    self.labelTree(x)

    def makeJobLists(self, elem):
        l = list(elem)
        if len(l):
            jlist = L()
            jlist.tag = elem.tag
            for x in l:
                jlist.append(x.attrib['name'])
                l2 = list(x)
                if len(l2):
                    self.makeJobLists(x)

        if len(jlist):
            jobs = " ".join(jlist)
            elem.attrib['joblist'] = jobs
            self.dagDict[elem.attrib['name']] = jlist

    def expand(self, jlist):
        for n, i in enumerate(jlist):
            if self.dagDict.get(str(i)):
                jlist[n] = self.dagDict.get(str(i))
        for n, i in enumerate(jlist):
            if isinstance(i, list):
                jlist[n] = self.expand(i)
        return jlist

    def getJobs(self, jlist, ndx=0):
        tag = getattr(jlist, 'tag', False)
        if tag == 'parallel':
            j = ''
            for j1 in jlist:
                j += self.getJobs(j1, ndx)
                j += ' '
            return j
        elif tag == 'serial':
            return self.getJobs(jlist[ndx], ndx)
        else:
            return jlist

    def generateParentChildList(self, jlist):
        par_or_ser = getattr(jlist, 'tag', False)
        if par_or_ser:
            for n, i in enumerate(jlist):

                if n == 0:
                    self.generateParentChildList(jlist[n])

                elif n > 0:

                    p = self.getJobs(jlist[n - 1], ndx=-1)
                    self.generateParentChildList(jlist[n - 1])

                    c = self.getJobs(jlist[n], ndx=0)
                    self.generateParentChildList(jlist[n])

                    if par_or_ser == 'serial':
                        pc = "parent %s child %s" % (p, c)
                        if pc not in self.pcList:
                            self.pcList.append(pc)

    def printJobRelationships(self, outFile, args=None):
        with open(outFile, "a") as f:
            for line in self.pcList:
                f.write("%s\n" % line)
        f.close()
        if args and args.generateSummary:
            f = open(outFile,"a")
            cf = self.writeDummyCmdFile()
            l = "FINAL JOB_FINISH %s \n" % cf
            f.write(l)
            l = "SCRIPT POST JOB_FINISH %s %s %s\n" %(args.summary_script,
                                                      cf,
                                                      os.path.basename(outFile))
            f.write(l)
            f.close()

    def reportState(self):
        print "processingSerial:%s processingParallel:%s" %\
            (self.processingSerial, self.processingParallel)
        print self.jobList
        print self.jobDict

    def digestInputFile(self, args):
        # strip out comments starting with '#'
        infile = str(args.inputFile)
        xmlfile = "%s.xml" % infile
        r = re.compile("#.*")
        plist = []
        jobsub_commands = ['jobsub ', 'dagsub ', 'jobsub_submit ', 'jobsub_submit_dag ' ]
        if len(sys.argv) > 1:
            f = open(infile, "r")
            x = open(xmlfile, "w")
            x.write("<dag>\n")
            i = 0
            j = 0
            for line in f:
                line = line.strip()
                line = r.sub('', line)
                #print "%s  %s line:%s " %(infile, os.getpid(), line)
                if len(line) > 0:
                    for cmd in jobsub_commands:
                        if cmd in line:
                            #pass
                            l2=line.replace("--","-")
                            x.write("<!-- %s -->\n" % l2)
                            #print 'added <!-- %s --> to %s %s'%(l2,xmlfile,os.getpid())

                if self.startSerial(line):
                    x.write('<serial>\n')
                    pass
                elif self.endSerial(line):
                    x.write('</serial>\n')
                elif self.startParallel(line):
                    x.write('<parallel>\n')
                    plist = []
                elif self.endParallel(line):
                    x.write('</parallel>\n')
                    self.jobList.append(plist)
                elif self.isInMacros(line):
                    self.processMacro(line)
                elif self.isInBeginJob(line):
                    self.processBeginJob(line)
                elif self.isInFinishJob(line):
                    self.processFinishJob(line)

                elif len(line) > 0:
                    for mac in self.macroList:
                        line = line.replace(mac, self.macroDict[mac])
                    val = ""
                    j += 1
                    os.environ['JOBSUBJOBSECTION'] = "%s" % j
                    passedArgs = ' '.join(args.passedArgs)
                    if 'jobsub_submit ' in line:
                        line = line.replace("jobsub_submit ", 'jobsub ')
                    if 'jobsub ' in line:
                        #print "before %s line=%s" % (os.getpid(), line)
                        passedArgs = """ -e JOBSUBJOBSECTION --lines '+JobsubJobSection=\\\"%s\\\"' %s """ % (
                        j, passedArgs)
                        repVal = "jobsub -n %s " % passedArgs
                        line = line.replace("jobsub ", repVal)
                        #print "after %s line=%s" % (os.getpid(), line)
                    if 'jobsub_submit_dag ' in line:
                        line = line.replace("jobsub_submit_dag ", "dagsub ")

                    if 'dagsub ' in line:
                        #print "before %s line=%s" % (os.getpid(), line)
                        repVal = "dagsub %s " % passedArgs
                        line = line.replace("dagsub ", repVal)
                        line = line.replace(" -s ", "")
                        line = line.replace("${JOBSUB_EXPORTS}", "")

                        #print "after %s line=%s" % (os.getpid(), line)
                    #print "%s executing: %s"% (os.getpid(),line)
                    (retVal, val) = commands.getstatusoutput(line)
                    #print "retVal: %s val:%s" %(retVal, val)
                    print val
                    if retVal:
                        print "error processing command %s" % line
                        print val
                        sys.exit(1)
                    else:
                        condor_cmd = ''
                        condor_cmd_list = []
                        biglist = val.split()
                        #print "biglist %s"%biglist
                        ncmds = 0
                        i = 0
                        for word in biglist:
                            if ".cmd" in word[-4:] or ".dag" in word[-4:] and word not in condor_cmd_list:
                                ncmds = ncmds + 1
                                condor_cmd = word
                                if ".dag" in word[-4:]:
                                    condor_cmd = os.path.basename(word) + ".condor.sub"
                                jobName = "Jb_%d_%d" % (j, i)
                                xml = """<job name="%s" cmd="%s" />\n""" % (jobName, condor_cmd)
                                #print "%s %s:xml=%s"%(os.getpid(), xmlfile, xml)
                                x.write(xml)
                                self.jobNameList.append(jobName)
                                self.jobDict[condor_cmd] = jobName
                                self.jobNameDict[jobName] = condor_cmd
                                condor_cmd_list.append(condor_cmd)
                                #print "condor_commands %s" % condor_cmd_list
                                i += 1
                        if self.processingSerial:
                            #jobList.append(tuple(condor_cmd_list))
                            self.jobList.append(tuple(condor_cmd_list))
                        if self.processingParallel:
                            plist.append(tuple(condor_cmd_list))
                        if (self.redundancy != 0 and self.redundancy != len(condor_cmd_list)):
                            print "ERROR: different number of '.cmd' files detected"
                            #print "between jobs in input file! This will generate"
                            #print "an incorrect DAG!  aborting......"
                            # sys.exit(-1)
                            self.redundancy = len(condor_cmd_list)
                        else:
                            self.redundancy = len(condor_cmd_list)
                        self.condor_cmd_list.extend(condor_cmd_list)
                        #print "condor_cmd_list: %s" % self.condor_cmd_list
                        # reportState()
            x.write('</dag>\n')
            x.close()

            tree = ET.parse(xmlfile)
            root = tree.getroot()
            self.labelTree(root)
            self. makeJobLists(root)

            cntr = 0
            for line in self.beginJobList:
                for mac in self.macroList:
                    line = line.replace(mac, self.macroDict[mac])
                    # print line
                    self.beginJobList[cntr] = line
                cntr += 1
            cntr = 0
            for line in self.finishJobList:
                for mac in self.macroList:
                    line = line.replace(mac, self.macroDict[mac])
                    # print line
                    self.finishJobList[cntr] = line
                cntr += 1

    def getJobName(self, jlist, i, j=0):

        if isinstance(jlist[i], tuple):
            retval = self.jobDict[jlist[i][j]]

        elif isinstance(jlist[i], list):
            retval = ""
            for l in jlist[i]:
                retval = retval + " " + self.getJobName(l, 0, j)
        else:

            retval = self.jobDict[jlist[j]]

        return retval

    def generateDependencies(self, outputFile, jlist):
        f = open(outputFile, "a")
        jend = len(jlist)
        i = 0

        if len(self.beginJobList) > 0:
            j = 0
            while(j < self.redundancy):
                l = "parent JOB_BEGIN child %s\n" % self.getJobName(
                    jlist, i, j)
                f.write(l)
                j += 1

        while (i < jend - 1):
            j = 0
            while(j < self.redundancy):
                l = "parent %s child %s\n" %\
                    (self.getJobName(jlist, i, j), self.getJobName(jlist, i + 1, j))
                f.write(l)
                j += 1
            i += 1

        if len(self.finishJobList) > 0:
            j = 0

            while(j < self.redundancy):
                l = "parent %s child JOB_FINISH\n" % self.getJobName(
                    jlist, i, j)
                f.write(l)
                j += 1

        f.close()

    def writeDummyCmdFile(self):

        excluded = ['transfer_input_files',
                    'queue',
                    'transfer_output',
                    'transfer_output_files',
                    ]

        now = datetime.datetime.now()
        filebase = "%s%02d%02d_%02d%02d%02d" % (now.year, now.month,
                                                now.day, now.hour,
                                                now.minute, now.second)
        cmd_file_name = "dummy%s.cmd" % (filebase)
        cmd_file = cmd_file_dummy.format(filebase)
        
        f = open(cmd_file_name, "w")
        f.write(cmd_file)
        if self.condor_cmd_list and os.path.exists(self.condor_cmd_list[-1]):
            jdf = open(self.condor_cmd_list[-1], "r")
            append = False
            for line in jdf:
                if not append and line[0:11].lower() == "environment":
                    append = True
                if append:
                    words = line.split()
                    if words and words[0].lower() not in excluded:
                        f.write(line)
            jdf.close()
        else:
            f.write("requirements = True\n")

        f.write("queue\n")
        f.close()
        return cmd_file_name

    def generateDag(self, args=None):

        if args:
            outputFile = args.outputFile
        f = open(outputFile, "w")
        l = "DOT %s.dot UPDATE\n" % os.path.basename(outputFile)
        f.write(l)

        if len(self.beginJobList) > 0:

            l = "JOB JOB_BEGIN %s\n" % self.writeDummyCmdFile()
            f.write(l)

        # for n in self.jobNameList:
        #    l = "JOB " + n + " "+ self.jobNameDict[n]+"\n"
        #    f.write(l)

        for k in sorted(self.nodeDict.keys()):
            e = self.nodeDict[k]
            if e.tag == 'job':
                f.write("JOB %s %s\n" % (k, os.path.basename(e.attrib['cmd'])))
                if args.continueOnFailure:
                    f.write("SCRIPT POST %s %s\n" % (k, args.dummy_script))

        if len(self.finishJobList) > 0:
            time.sleep(1)
            l = "JOB JOB_FINISH %s \n" % self.writeDummyCmdFile()
            f.write(l)

        if len(self.beginJobList) > 0:
            l = "SCRIPT PRE JOB_BEGIN %s \n" % self.beginJobList[1]
            f.write(l)
        if len(self.finishJobList) > 0:
            l = "SCRIPT POST JOB_FINISH %s \n" % self.finishJobList[1]
            f.write(l)
            
        f.close()
        # self.generateDependencies(outputFile,self.jobList)
        jobList = L(self.dagDict.get('dag'), tag='serial')
        self.expand(jobList)
        self.generateParentChildList(jobList)
        self.printJobRelationships(outputFile,args)


# this should really use optparse but too many of the input
# options are malformed for optparse  - not enough dashes etc
# also --subgroups has to go both to this programs input and on to jobsub
#
# parse out the ones we intend to use and pass the rest on to jobsub
#
class ArgParser(object):

    def __init__(self, cfp):
        cfp.findConfigFile()
        self.inputFile = None
        self.outputFile = ""
        self.runDag = False
        self.viewDag = False
        self.maxJobs = 0
        self.passedArgs = None
        self.schedd = os.environ.get("SCHEDD")
        self.submitHost = os.environ.get("SUBMIT_HOST")
        self.group = os.environ.get("GROUP")
        self.subgroup = None
        self.generateSummary = False
        self.continueOnFailure = False
        self.pwd = os.path.dirname(os.path.realpath(__file__))
        self.passedArgs = []
        self.verbose = ""
        allowed = cfp.supportedGroups()

        if self.group not in allowed:
            print "ERROR do not run this script as member of group %s" % self.group
            print "export GROUP=one of %s and try again" % allowed
            sys.exit(-1)

        i = 0
        args = sys.argv
        passedArgs = []
        argLen = len(sys.argv)

        while i < argLen:
            arg = args[i]
            if arg in ["--h", "-h", "--help", "-help"]:
                self.printHelp()
            elif arg in ["-man", "-manual"]:
                self.printManual()
            elif arg in ["--inputFile", "-input_file", "-i"]:
                if os.path.isfile(args[i + 1]):
                    self.inputFile = args[i + 1]
                    i += 1
            elif arg in ["--outputFile", "-output_file", "-o"]:
                self.outputFile = args[i + 1]
                i += 1
            elif arg in ["--maxConcurrent", "--maxRunning", "-max_running", "-m"]:
                self.maxJobs = int(args[i + 1])
                i += 1
            elif arg in ["--submit", "-submit", "-s"]:
                self.runDag = True
            elif arg == "--subgroup":
                self.subgroup = args[i + 1]
                self.passedArgs.append("--subgroup")
                self.passedArgs.append(self.subgroup)
                i += 1
            elif arg in ["--generate-email-summary"]:
                self.generateSummary = True
                self.continueOnFailure = True
                self.dummy_script = "/opt/jobsub/server/tools/returnOK.sh"
                self.summary_script = "%s/%s" % (self.pwd,"summary.sh")

            elif arg in ["--continue-on-failure"]:
                self.continueOnFailure = True
                self.dummy_script = "/opt/jobsub/server/tools/returnOK.sh"

            elif arg in ["-v", "--verbose"]:
                self.verbose = '--verbose' 
            elif i > 0:
                self.passedArgs.append(arg)
            i += 1

        if self.inputFile is None:
            i = 0
            fileOpts = ['-L', '--log_file',
                        '--tar_file_name', '-f', '-i', '-t']
            for arg in self.passedArgs:
                if os.path.isfile(arg):
                    if (i == 0) or ((i > 0) and (self.passedArgs[i - 1] not in fileOpts)):
                        self.inputFile = self.passedArgs[i]
                        del self.passedArgs[i]
                        break
                i += 1

        if self.outputFile == "":
            cmd = """date +%Y%m%d_%H%M%S"""
            # commands=JobUtils()
            (retVal, val) = commands.getstatusoutput(cmd)
            if retVal == 0:
                now = val.rstrip()
                condor_tmp = os.environ.get("CONDOR_TMP")
                home = os.environ.get("HOME")
                if condor_tmp == "" or condor_tmp == None:
                    self.outputFile = home + "/submit.%s.dag" % now
                else:
                    self.outputFile = condor_tmp + "/submit.%s.dag" % now
                # print "generated DAG saved as ", self.outputFile
            else:
                sys.stderr.write("error executing %s\n ") % cmd
                sys.stderr.write("%s\n ") % val
                sys.exit(1)

    def report(self):
        print "====================================="
        print "inputFile = ", self.inputFile
        print "outputFile = ", self.outputFile
        print "runDag =", self.runDag
        print "maxJobs =", self.maxJobs

    def printHelp(self):
        h = os.path.basename(sys.argv[0])
        helpFile = usage % (h, h)
        print helpFile
        sys.exit(0)

    def printManual(self):
        m = os.path.basename(sys.argv[0])
        df = """date +%Y%m%d_%H%M%S_%N"""
        manFile = manual 
        print manFile
        sys.exit(0)


class JobRunner(object):

    def __init__(self):
        pass



    def munge_jdf(self,condor_jdf):
        files = ",".join(os.listdir("."))
        transfer_files = "transfer_input_files = %s" % files
        orig_name = condor_jdf + ".orig"
        os.rename(condor_jdf, orig_name)
        fin = open(orig_name, "r")
        fout = open(condor_jdf, "w")
        for line in fin:
            if  'queue' in line:
                fout.write("%s\n" % transfer_files)
            fout.write("%s" % line)
        fin.close()
        fout.close()




    #def doSubmit(self, args=None):
    def generateSubmit(self, args=None):
        condor_jdf = args.outputFile + ".condor.sub"
        if os.path.exists(condor_jdf):
            return
        cmd = ""
        # commands=JobUtils()
        (retVal, host) = commands.getstatusoutput("uname -n")
        ups_shell = os.environ.get("UPS_SHELL")
        condor_tmp = os.environ.get("CONDOR_TMP")
        jobsub_exports = os.environ.get("JOBSUB_EXPORTS")
        os.chdir(condor_tmp)
        remote_schedd = False
        local_schedd_name = ""
        if ups_shell is None:
            ups_shell = "sh"
        if args.schedd:
            parts = args.schedd.split('@')
            schedd_host = parts[-1]
            if schedd_host != args.submitHost:
                remote_schedd = True
            else:
                if parts[0] != parts[-1]:
                    local_schedd_name = parts[0]
        else:
            args.schedd = args.submitHost

        if local_schedd_name:
            cmd1 = "condor_config_val SCHEDD.%s.SCHEDD_ADDRESS_FILE" % local_schedd_name
            cmd2 = "condor_config_val SCHEDD.%s.SCHEDD_DAEMON_AD_FILE" % local_schedd_name
            (retVal, addr_file) = commands.getstatusoutput(cmd1)
            (retVal, daemon_file) = commands.getstatusoutput(cmd2)
            add_spec = " -schedd-address-file %s  -schedd-daemon-ad-file %s" % (addr_file, daemon_file)
        else:
            add_spec = ""
        cmd = """condor_submit_dag %s %s -no_submit  """ % (args.verbose,add_spec)
        cmd += """ -dont_suppress_notification  -insert_sub_file dag.frag """
        if args.maxJobs > 0:
            cmd = cmd + " -maxjobs %d " % args.maxJobs
        usr = os.environ.get("USER")
        grp = os.environ.get("GROUP")

        subgroup = None
        if args is not None:
            subgroup = args.subgroup


        frag = open("dag.sub.frag","a")
        for itm in jobsub_exports.split('-l'):
            itm = itm.split('--environment')[0]
            itm = itm.split('-e')[0]
            itm = itm.replace("\\","")
            itm = itm.replace("'",'')
            itm = itm.replace(" = ","=")
            itm = itm.strip()
            itm = itm.replace('\r','').replace('\n','')
            frag.write("%s\n"%itm)
        frag.close()    
        sortcmd = "sort -u dag.sub.frag -o dag.frag"
        commands.getstatusoutput(sortcmd)
        cmd += os.path.basename(args.outputFile)
        if args.verbose:
       	    print "jobsub_submit_dag  executing %s" % cmd
        (retVal, val) = commands.getstatusoutput(cmd)
        if args.verbose or retVal:
            print val

        if retVal:
            print "ERROR executing %s" % cmd
            print val
            retVal = retVal % 256
            if retVal == 0:
                retVal = 1
                sys.exit(retVal)
        print os.path.basename(args.outputFile) + ".condor.sub"

    def doSubmit(self, args=None):
        remote_schedd = False
        local_schedd_name = ""
        if args.schedd:
            parts = args.schedd.split('@')
            schedd_host = parts[-1]
            if schedd_host != args.submitHost:
                remote_schedd = True
        condor_jdf = args.outputFile + ".condor.sub"
        if remote_schedd:
            self.munge_jdf(condor_jdf)
            cmd = "condor_submit -remote %s %s"%(args.schedd, condor_jdf)
        elif args.schedd:
            cmd = "condor_submit -name %s %s"%(args.schedd, condor_jdf)
        else:
            cmd = "condor_submit  %s"%(condor_jdf)
        print "executing %s " % cmd
        (retVal, val) = commands.getstatusoutput(cmd)
        if retVal:
            print "ERROR executing %s" % cmd
            print val
            retVal = retVal % 256
            if retVal == 0:
                retVal = 1
            sys.exit(retVal)
        print val
        


if __name__ == '__main__':
    c = JobsubConfigParser()
    args = ArgParser(c)
    d = DagParser()
    d.digestInputFile(args)
    d.generateDag(args)
    j = JobRunner()
    j.generateSubmit(args)
    if args.runDag:
        j.doSubmit(args)
